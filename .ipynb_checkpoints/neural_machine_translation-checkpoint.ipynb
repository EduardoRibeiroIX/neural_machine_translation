{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3754c1ec",
   "metadata": {},
   "source": [
    "## Uma Rede Codificador-Decodificador para Tradução Neural de Máquina\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cd8157",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pathlib in /home/jupyter-eduardo/.local/lib/python3.9/site-packages (1.0.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pathlib in /home/jupyter-eduardo/.local/lib/python3.9/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pathlib\n",
    "!pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b55acb7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 09:12:59.590639: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-01 09:12:59.591725: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 09:12:59.607600: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-01 09:12:59.607610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-01 09:12:59.608069: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-01 09:12:59.610738: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-01 09:12:59.611044: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 09:12:59.913471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f7220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom doesn't look too upset to me. => Vamos deixar o Tom fazer isso de novo.\n",
      "Now I recognize you. => Agora estou te reconhecendo.\n",
      "I want Tom to win. => Eu quero que Tom ganhe.\n"
     ]
    }
   ],
   "source": [
    "path = str(os.getcwd())\n",
    "\n",
    "text = (Path(path) / \"dataset.txt\").read_text()\n",
    "\n",
    "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
    "\n",
    "np.random.shuffle(pairs)\n",
    "\n",
    "sentences_en, sentences_es = zip(*pairs) # separates the pairs into 2 lists\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    print(sentences_en[i], \"=>\", sentences_es[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72f74e1d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 09:13:26.920356: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-01 09:13:26.920447: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-01 09:13:26.922262: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 1000\n",
    "max_length = 50\n",
    "\n",
    "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
    " vocab_size, output_sequence_length=max_length)\n",
    "\n",
    "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
    " vocab_size, output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4317c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'startofseq', 'endofseq', 'tom', 'que', 'o', 'não', 'eu', 'de']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_en.adapt(sentences_en)\n",
    "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])\n",
    "text_vec_layer_en.get_vocabulary()[:10]\n",
    "text_vec_layer_es.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f88c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.constant(sentences_en[:100_000])\n",
    "X_valid = tf.constant(sentences_en[100_000:])\n",
    "\n",
    "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
    "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
    "\n",
    "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
    "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4a29add",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "817484a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "\n",
    "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
    "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
    "\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    " mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    " mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1164cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2c4851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7629e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "3125/3125 [==============================] - 870s 278ms/step - loss: 2.9508 - accuracy: 0.4227 - val_loss: 2.1917 - val_accuracy: 0.5188\n",
      "Epoch 2/12\n",
      "3125/3125 [==============================] - 865s 277ms/step - loss: 1.8655 - accuracy: 0.5721 - val_loss: 1.6606 - val_accuracy: 0.6088\n",
      "Epoch 3/12\n",
      "3125/3125 [==============================] - 870s 278ms/step - loss: 1.4511 - accuracy: 0.6454 - val_loss: 1.4416 - val_accuracy: 0.6513\n",
      "Epoch 4/12\n",
      "3125/3125 [==============================] - 861s 276ms/step - loss: 1.2150 - accuracy: 0.6916 - val_loss: 1.3331 - val_accuracy: 0.6707\n",
      "Epoch 5/12\n",
      "3125/3125 [==============================] - 863s 276ms/step - loss: 1.0492 - accuracy: 0.7250 - val_loss: 1.2900 - val_accuracy: 0.6816\n",
      "Epoch 6/12\n",
      "3125/3125 [==============================] - 866s 277ms/step - loss: 0.9153 - accuracy: 0.7538 - val_loss: 1.2747 - val_accuracy: 0.6876\n",
      "Epoch 7/12\n",
      "3125/3125 [==============================] - 865s 277ms/step - loss: 0.8005 - accuracy: 0.7799 - val_loss: 1.2883 - val_accuracy: 0.6867\n",
      "Epoch 8/12\n",
      "3125/3125 [==============================] - 868s 278ms/step - loss: 0.7001 - accuracy: 0.8025 - val_loss: 1.3160 - val_accuracy: 0.6860\n",
      "Epoch 9/12\n",
      "3125/3125 [==============================] - 863s 276ms/step - loss: 0.6120 - accuracy: 0.8243 - val_loss: 1.3635 - val_accuracy: 0.6824\n",
      "Epoch 10/12\n",
      "3125/3125 [==============================] - 863s 276ms/step - loss: 0.5366 - accuracy: 0.8433 - val_loss: 1.4007 - val_accuracy: 0.6811\n",
      "Epoch 11/12\n",
      "3125/3125 [==============================] - 870s 279ms/step - loss: 0.4734 - accuracy: 0.8597 - val_loss: 1.4479 - val_accuracy: 0.6791\n",
      "Epoch 12/12\n",
      "3125/3125 [==============================] - 861s 275ms/step - loss: 0.4214 - accuracy: 0.8732 - val_loss: 1.5055 - val_accuracy: 0.6749\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'modelo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnadam\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m  metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mfit((X_train, X_train_dec), Y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m,\n\u001b[1;32m      8\u001b[0m  validation_data\u001b[38;5;241m=\u001b[39m((X_valid, X_valid_dec), Y_valid))\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodelo\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtradutor.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'modelo' is not defined"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    " outputs=[Y_proba])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    " metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=12,\n",
    " validation_data=((X_valid, X_valid_dec), Y_valid))\n",
    "\n",
    "modelo.save(\"tradutor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0408dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence_en):\n",
    "     translation = \"\"\n",
    "     for word_idx in range(max_length):\n",
    "         X = np.array([sentence_en]) # encoder input\n",
    "         X_dec = np.array([\"startofseq \" + translation]) # decoder input\n",
    "         y_proba = model.predict((X, X_dec))[0, word_idx] # last token's probas\n",
    "         predicted_word_id = np.argmax(y_proba)\n",
    "         predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
    "         if predicted_word == \"endofseq\":\n",
    "             break\n",
    "         translation += \" \" + predicted_word\n",
    "     return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2770088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 753ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta el fútbol'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like soccer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641af45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor = ['I like to eat', 'We are friends', 'My son is reading', 'I dont like my family', 'I dont know read']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a20452e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m frase \u001b[38;5;129;01min\u001b[39;00m vetor:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtranslate\u001b[49m(frase))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'translate' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for frase in vetor:\n",
    "    print(translate(frase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f673cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea76934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075608e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
