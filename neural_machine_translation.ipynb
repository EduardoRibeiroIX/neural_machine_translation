{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07V6EkEnr5mK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07V6EkEnr5mK",
    "outputId": "a9e35f0a-d1de-46ed-dbc4-c0a5b2e9e729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pasta ./dataset.zip foi descompactada em ./.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "caminho_zip = './dataset.zip'\n",
    "diretorio_destino = './'\n",
    "\n",
    "# Certifique-se de que o diretório de destino exista ou crie-o\n",
    "if not os.path.exists(diretorio_destino):\n",
    "    os.makedirs(diretorio_destino)\n",
    "\n",
    "# Descompactar o arquivo .zip\n",
    "with zipfile.ZipFile(caminho_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(diretorio_destino)\n",
    "\n",
    "print(f'A pasta {caminho_zip} foi descompactada em {diretorio_destino}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3754c1ec",
   "metadata": {
    "id": "3754c1ec"
   },
   "source": [
    "## Uma Rede Codificador-Decodificador para Tradução Neural de Máquina\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cd8157",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07cd8157",
    "outputId": "032ed54e-c4b8-4c37-936d-9b253a6b0b73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b55acb7",
   "metadata": {
    "collapsed": true,
    "id": "4b55acb7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oR7bbScQp_Mi",
   "metadata": {
    "id": "oR7bbScQp_Mi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('eng-por.txt', sep='\\t')\n",
    "df.columns = ['Ingles', 'Portugues', 'descatar']\n",
    "df = df.drop(columns=['descatar'])\n",
    "df.columns = ['', '']\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv('dataset.txt', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f7220a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10f7220a",
    "outputId": "0b81da79-78ac-4361-9ffc-e0b8a9cfe081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The station was deserted. => A estação estava deserta.\n",
      "We are in the era of atomic energy. => Estamos na era da energia nuclear.\n",
      "Can I borrow your car? => Posso pegar emprestado o teu carro?\n"
     ]
    }
   ],
   "source": [
    "path = str(os.getcwd())\n",
    "\n",
    "text = (Path(path) / \"dataset.txt\").read_text()\n",
    "\n",
    "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
    "\n",
    "np.random.shuffle(pairs)\n",
    "\n",
    "sentences_en, sentences_es = zip(*pairs) # separates the pairs into 2 lists\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    print(sentences_en[i], \"=>\", sentences_es[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f74e1d",
   "metadata": {
    "collapsed": true,
    "id": "72f74e1d"
   },
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_length = 50\n",
    "\n",
    "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
    " vocab_size, output_sequence_length=max_length)\n",
    "\n",
    "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
    " vocab_size, output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4317c7c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4317c7c",
    "outputId": "13f5f367-d6f4-4348-f759-bec230891012"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'startofseq', 'endofseq', 'tom', 'que', 'o', 'não', 'eu', 'de']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_en.adapt(sentences_en)\n",
    "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])\n",
    "text_vec_layer_en.get_vocabulary()[:10]\n",
    "text_vec_layer_es.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f88c7b8",
   "metadata": {
    "id": "9f88c7b8"
   },
   "outputs": [],
   "source": [
    "X_train = tf.constant(sentences_en[:100_000])\n",
    "X_valid = tf.constant(sentences_en[100_000:])\n",
    "\n",
    "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
    "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
    "\n",
    "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
    "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a29add",
   "metadata": {
    "id": "b4a29add"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "817484a3",
   "metadata": {
    "id": "817484a3"
   },
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "\n",
    "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
    "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
    "\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    " mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    " mask_zero=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1164cfd",
   "metadata": {
    "id": "e1164cfd"
   },
   "outputs": [],
   "source": [
    "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2c4851f",
   "metadata": {
    "id": "a2c4851f"
   },
   "outputs": [],
   "source": [
    "encoder = tf.keras.layers.LSTM(512, return_state=True)\n",
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "\n",
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7629e29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7629e29",
    "outputId": "1042e0df-1c95-4696-b938-1f6160a452e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 119s 34ms/step - loss: 0.3313 - accuracy: 0.8936 - val_loss: 1.3258 - val_accuracy: 0.7109\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 87s 28ms/step - loss: 0.2950 - accuracy: 0.9056 - val_loss: 1.3638 - val_accuracy: 0.7098\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 85s 27ms/step - loss: 0.2770 - accuracy: 0.9111 - val_loss: 1.4004 - val_accuracy: 0.7065\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 86s 28ms/step - loss: 0.2645 - accuracy: 0.9149 - val_loss: 1.4335 - val_accuracy: 0.7076\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 84s 27ms/step - loss: 0.2516 - accuracy: 0.9190 - val_loss: 1.4650 - val_accuracy: 0.7057\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 87s 28ms/step - loss: 0.2445 - accuracy: 0.9209 - val_loss: 1.4910 - val_accuracy: 0.7051\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 88s 28ms/step - loss: 0.2370 - accuracy: 0.9234 - val_loss: 1.5164 - val_accuracy: 0.7045\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 87s 28ms/step - loss: 0.2307 - accuracy: 0.9256 - val_loss: 1.5479 - val_accuracy: 0.7047\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 86s 28ms/step - loss: 0.2277 - accuracy: 0.9265 - val_loss: 1.5589 - val_accuracy: 0.7039\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 83s 27ms/step - loss: 0.2231 - accuracy: 0.9283 - val_loss: 1.5788 - val_accuracy: 0.7029\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    " outputs=[Y_proba])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    " metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
    " validation_data=((X_valid, X_valid_dec), Y_valid))\n",
    "\n",
    "model.save(\"modelo_tradutor\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0408dc7",
   "metadata": {
    "id": "b0408dc7"
   },
   "outputs": [],
   "source": [
    "def translate(sentence_en):\n",
    "     translation = \"\"\n",
    "     for word_idx in range(max_length):\n",
    "         X = np.array([sentence_en]) # encoder input\n",
    "         X_dec = np.array([\"startofseq \" + translation]) # decoder input\n",
    "         y_proba = model.predict((X, X_dec))[0, word_idx] # last token's probas\n",
    "         predicted_word_id = np.argmax(y_proba)\n",
    "         predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
    "         if predicted_word == \"endofseq\":\n",
    "             break\n",
    "         translation += \" \" + predicted_word\n",
    "     return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2770088",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "d2770088",
    "outputId": "32c938f5-f5d1-4116-96ad-3fb1df182657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'gosto de futebol'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like soccer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "641af45e",
   "metadata": {
    "id": "641af45e"
   },
   "outputs": [],
   "source": [
    "vetor = ['I like to eat', 'They are going', 'My children is good', 'I dont like my family', 'I dont know read']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a20452e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a20452e6",
    "outputId": "4525e3d6-cd91-40f4-bf6a-c43dbce2d42f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "gosto de comer\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "elas estão indo\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "meus filhos são bons\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "eu não gosto da minha família\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "eu não sei ler\n"
     ]
    }
   ],
   "source": [
    "for frase in vetor:\n",
    "    print(translate(frase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24f673cf",
   "metadata": {
    "id": "24f673cf"
   },
   "outputs": [],
   "source": [
    "modelo_pt = tf.keras.models.load_model(\"modelo_tradutor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea76934",
   "metadata": {
    "id": "eea76934"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075608e9",
   "metadata": {
    "id": "075608e9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
